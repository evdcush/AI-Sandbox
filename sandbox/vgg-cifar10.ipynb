{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  NETWORK  ##\n",
    "class ConvNormRelu(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c_in, c_out, kernel_size=3, padding=1)\n",
    "        self.norm = nn.BatchNorm2d(c_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.norm(self.conv(x)))\n",
    "        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, cfg=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvNormRelu(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = ConvNormRelu(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = ConvNormRelu(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = ConvNormRelu(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=1, stride=2)\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.pool1(self.conv1(x))\n",
    "        h = self.pool2(self.conv2(h))\n",
    "        h = self.pool3(self.conv3(h))\n",
    "        h = self.pool4(self.conv4(h))\n",
    "        h = self.avg_pool(h)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        return self.classifier(h)      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  DATA  ##\n",
    "\n",
    "DATA_DIR = os.environ['HOME'] + '/.Data'\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Datasets & loaders.\n",
    "trainset = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "\n",
    "testset = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  MODEL  ##\n",
    "DEVICE = 'cuda'\n",
    "net = VGG()\n",
    "net.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  TRAINING  ##\n",
    "best_acc = 0\n",
    "\n",
    "def train(epoch):\n",
    "    print(f\"{epoch = }\")\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        #print(f\"{i = }\\nLoss: {train_loss / (i+1): .3f} | Acc: {100 * correct / total: .3f}\")\n",
    "    \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(epoch, chkpt_dir='/home/evan/Checkpoints'):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = total = 0\n",
    "    for i, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"Test Loss: {test_loss / (i+1): .3f} | Acc: {100 * correct / total: .3f}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_acc:\n",
    "        print(\"Saving...\")\n",
    "        state = dict(\n",
    "            net=net.state_dict(),\n",
    "            acc=acc,\n",
    "            epoch=epoch\n",
    "        )\n",
    "        if not os.path.isdir(chkpt_dir):\n",
    "            os.mkdir(chkpt_dir)\n",
    "        torch.save(state, chkpt_dir + '/chkpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 20):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
