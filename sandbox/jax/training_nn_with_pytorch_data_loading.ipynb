{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd97fbed",
   "metadata": {},
   "source": [
    "# Training a Simple Neural Network with PyTorch Data Loading\n",
    "Reference doc: https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb53d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from torch import utils\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "from jax.scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729fffcc",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465c3c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "    \"\"\" Generate randomly initialized weights & biases. \"\"\"\n",
    "    w_key, b_key = random.split(key)\n",
    "    w = scale * random.normal(w_key, (n, m))\n",
    "    b = scale * random.normal(b_key, (n,))\n",
    "    return w, b\n",
    "\n",
    "def init_network_params(sizes, key):\n",
    "    \"\"\" Init all layers for a fully-connected nn with sizes. \"\"\"\n",
    "    keys = random.split(key, len(sizes))\n",
    "    layer_args = zip(sizes[:-1], sizes[1:], keys)\n",
    "    return [random_layer_params(*args) for args in layer_args]\n",
    "\n",
    "# Hyperparams.\n",
    "layer_sizes = [784, 512, 512, 10]\n",
    "step_size = 0.01\n",
    "num_epochs = 8\n",
    "batch_size = 128\n",
    "n_targets = 10\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f5a708",
   "metadata": {},
   "source": [
    "### Auto-batching predictions\n",
    "Let us first define our prediction function.\n",
    "NB: we are defining this for a *single* image example, then using JAX's `vmap` function to automatically handle mini-batches (with no performance penalty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6d62c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict(params, image):\n",
    "    # per-sample predictions\n",
    "    activations = image\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "    \n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(final_w, activations) + final_b\n",
    "    return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf6d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# This works on single examples.\n",
    "k = random.PRNGKey(1)\n",
    "random_flattened_image = random.normal(k, (28 * 28,))\n",
    "preds = predict(params, random_flattened_image)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef4c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
